"""Question Generation, use pre-trained support vector machine identify question quality
Note: SVM Accuracy on Training Set 75%
	  SVM Accuracy on 10-fold CV: 66%
	  Parameter: rbf kernel, c=300, gamma=0.001
Code:
"""
import os
import itertools
from nltk.parse import stanford
from nltk.internals import find_jars_within_path
from .sentence_selection import SentenceSelection


class GapSelection:

    def __init__(self):
    
        os.environ['SENTENCE_RATIO'] = "0.05"
        os.environ['STANFORD_JARS'] = "/Users/Manasa/Desktop/aqgmod/stanford-models/"
        os.environ['STANFOR_PARSER_CLASSPATH'] = "/Users/Manasa/Desktop/aqgmod/stanford-models/stanford-parser-3.9.1-models.jar"
        os.environ['STANFORD_NER_CLASSPATH'] = "/Users/Manasa/Desktop/aqgmod/stanford-models/stanford-ner.jar"
        os.environ['STANFORD_POS_CLASSPATH'] = "/Users/Manasa/Desktop/aqgmod/stanford-models/english-bidirectional-distsim.tagger"
        os.environ['STANFORD_POS_JAR'] = "/Users/Manasa/Desktop/aqgmod/stanford-models/stanford-postagger.jar"
        os.environ['STANFORD_PARSER'] = os.environ.get(
            'STANFORD_JARS')
        os.environ['STANFORD_MODELS'] = os.environ.get(
            'STANFORD_JARS')
        os.environ['CLASSPATH'] = os.environ.get(
        	'STANFORD_PARSER_CLASSPATH')
        self.model_path = os.environ.get(
            'STANFORD_JARS') + 'englishPCFG.ser.gz'

    def _prepare_parser(self):
        """Prepare stanford parser
        - Args:
        - Returns:
            parser: stanford parser
        """
        parser = stanford.StanfordParser(model_path=self.model_path)
        return parser

    def _parse(self, sentence):
        """Parse sentence into an syntatic tree
        - Args:
            sentence(str): string of current sentence 
        - Returns:
            parsed_sentence(list):list of Tree object syntactic tree
        """
        parser = self._prepare_parser()
        parsed_sentence = list(parser.raw_parse((sentence)))
        print('PARSED SENTENCE:   ', parsed_sentence)
        return parsed_sentence
        
    def _extract_gaps(self, sentence, tree):
        """Extract nouns, np, adjp from tree object
        - Args:
            sentence(str): current sentence
            tree(list): list of Tree object, correspond to sentence
        - - Returnss:
            candidates(list of dict): candidate questions generated by this sentence,
            e.g. [{'question':'the capital city of NL is _____', 'gap':'Amsterdam'}]
        """
        #try NNP 
        candidates = []
        candidate = {}
        entities1 = ['ADJP','VP','VB']
        entities1 = list(map(lambda x: list(x.subtrees(
            filter=lambda x: x.label() in entities1)), tree))[0]
        entities2 = ['NP']
        entities2 = list(map(lambda x: list(x.subtrees(
            filter=lambda x: x.label() in entities2)), tree))[0]
        entities = [entities1, entities2]
        entities = list(itertools.chain.from_iterable(entities))
        
        if len(entities) > 150:
            return False
        else:
            for entity in entities:
                candidate_gap = str(' '.join(entity.leaves()))
                sentence_copy = sentence
                # replace sentence candidate_gap with ___
                sentence_copy = sentence_copy.replace(candidate_gap, '_____')
                candidate['Sentence'] = sentence
                candidate['Question'] = sentence_copy
                candidate['Answer'] = candidate_gap
                if candidate_gap.strip() != sentence.strip():
                    candidates.append(candidate)
                candidate = {}
            print(candidates)
            return candidates
    '''
    def _extract_gaps(self, sentence, tree):
        candidates = []
        candidate = {}
        entities = {'NNP':'who', 'NP':'what'}
        entities = list(map(lambda x: list(x.subtrees(
            filter=lambda x: x.label() in entities1)), tree))[0]
        entities = list(itertools.chain.from_iterable(entities))
        
        if len(entities) > 50:
            return False
        else:
            for entity in entities:
                candidate_gap = str(' '.join(entity.leaves()))
                sentence_copy = sentence
                # replace sentence candidate_gap with ___
                sentence_copy = sentence_copy.replace(candidate_gap, '_____')
                candidate['Sentence'] = sentence
                candidate['Question'] = sentence_copy
                candidate['Answer'] = candidate_gap
                if candidate_gap.strip() != sentence.strip():
                    candidates.append(candidate)
                candidate = {}
            print(candidates)
            return candidates
    '''
    def get_candidates(self, sentences):
        """Main function, prepare sentences, parse sentence, extract gap
        - Args:
            sentences(dict): topically important sentences
        - - Returnss:
                candidates(list of dict): list of dictionary, e.g.
                [{'Sentence': .....,'Question':.....,'Answer':...},...]
        """
        candidates = []
        for sentence_id, sentence in sentences.items():
            tree = self._parse(sentence)
            current_sentence_candidates = self._extract_gaps(
                sentence, tree)  # build candidate questions
            if current_sentence_candidates == False:
                continue
            candidates = candidates + current_sentence_candidates
            print("building candidate question/answer pairs %d" % len(candidates))
            # clear current_sentence_candidates
            current_sentence_candidates = []
        return candidates
